import { createClient } from "@supabase/supabase-js";
import { OpenAI } from "npm:openai@^4.0.0";

const supabaseUrl = Deno.env.get("SUPABASE_URL") ?? "";
const supabaseKey = Deno.env.get("SERVICE_ROLE_KEY") ?? "";
const supabase = createClient(supabaseUrl, supabaseKey);
const openaiApiKey = Deno.env.get("OPENAI_API_KEY");
const openai = openaiApiKey ? new OpenAI({ apiKey: openaiApiKey }) : null;

const table = "frankie_memories";

Deno.serve(async (req: Request) => {
  const authHeader = req.headers.get("Authorization");
  if (!authHeader || authHeader !== `Bearer ${supabaseKey}`) {
    return new Response("Unauthorized", { status: 401 });
  }

  const url = new URL(req.url);
  const pathname = url.pathname;
  const method = req.method;

  try {
    if (pathname === "/memory") {
      if (method === "GET") {
        const memory_content = url.searchParams.get("memory_content");
        const tagsStr = url.searchParams.get("tags");
        const protocol = url.searchParams.get("protocol");
        const limit = parseInt(url.searchParams.get("limit") || "10");
        const offset = parseInt(url.searchParams.get("offset") || "0");

        let query = supabase.from(table).select("*").order("created_at", { ascending: false }).range(offset, offset + limit - 1);

        if (memory_content) query = query.ilike("memory_content", `%${memory_content}%`);
        if (tagsStr) {
          const tags = tagsStr.split(",").map(t => t.trim());
          query = query.contains("tags", tags);
        }
        if (protocol) query = query.eq("protocol", protocol);

        const { data, error } = await query;
        if (error) throw error;
        return new Response(JSON.stringify(data), { status: 200 });
      } else if (method === "POST") {
        const { memory_content, tags = [], protocol, embedding: providedEmbedding } = await req.json();
        let embedding = providedEmbedding;
        if (!embedding && openai) {
          const response = await openai.embeddings.create({ model: "text-embedding-ada-002", input: memory_content });
          embedding = response.data[0].embedding;
        }
        const insertData = { memory_content, tags, protocol, embedding };
        const { data, error } = await supabase.from(table).insert(insertData).select();
        if (error) throw error;
        return new Response(JSON.stringify(data[0]), { status: 200 });
      }
    } else if (pathname === "/memory_direct") {
      if (method === "POST") {
        const { memory_content, tags = [], protocol, embedding: providedEmbedding } = await req.json();
        let embedding = providedEmbedding;
        if (!embedding && openai) {
          const response = await openai.embeddings.create({ model: "text-embedding-ada-002", input: memory_content });
          embedding = response.data[0].embedding;
        }
        const insertData = { memory_content, tags, protocol, embedding };
        const { data, error } = await supabase.from(table).insert(insertData).select();
        if (error) throw error;
        return new Response(JSON.stringify(data[0]), { status: 200 });
      }
    } else if (pathname === "/memory_by_tags") {
      if (method === "GET") {
        const tagsStr = url.searchParams.get("tags");
        const tags = tagsStr ? tagsStr.split(",").map(t => t.trim()) : [];
        let query = supabase.from(table).select("*").order("created_at", { ascending: false });
        if (tags.length > 0) query = query.contains("tags", tags);
        const { data, error } = await query;
        if (error) throw error;
        return new Response(JSON.stringify(data), { status: 200 });
      }
    } else if (pathname === "/memory_search") {
      if (method === "GET") {
        const q = url.searchParams.get("q") || "";
        const { data, error } = await supabase.from(table).select("*").textSearch("memory_content", q, { config: "english", type: "websearch" }).order("created_at", { ascending: false });
        if (error) throw error;
        return new Response(JSON.stringify(data), { status: 200 });
      }
    } else if (pathname === "/memory_fuzzy") {
      if (method === "GET") {
        const q = url.searchParams.get("q") || "";
        const threshold = parseFloat(url.searchParams.get("threshold") || "0.3");
        const limit = parseInt(url.searchParams.get("limit") || "10");
        const { data, error } = await supabase.from(table).select(`*, similarity(memory_content, '${q}') as similarity`).gt("similarity", threshold).order("similarity", { ascending: false }).limit(limit);
        if (error) throw error;
        return new Response(JSON.stringify(data), { status: 200 });
      }
    } else if (pathname === "/memory_recent_per_tag") {
      if (method === "GET") {
        const { data, error } = await supabase.rpc("get_frankie_recent_per_tag");
        if (error) throw error;
        return new Response(JSON.stringify(data), { status: 200 });
      }
    } else if (pathname === "/memory_semantic") {
      if (method === "GET") {
        const q = url.searchParams.get("query");
        const threshold = parseFloat(url.searchParams.get("threshold") || "0.5");
        const count = parseInt(url.searchParams.get("count") || "10");
        if (!q || !openai) return new Response("Missing query or OpenAI key", { status: 400 });
        const response = await openai.embeddings.create({ model: "text-embedding-ada-002", input: q });
        const query_embedding = response.data[0].embedding;
        const vectorStr = `[${query_embedding.join(",")}]`;
        const { data, error } = await supabase.from(table).select(`*, (embedding <-> '${vectorStr}'::vector) AS distance`).lt("distance", threshold).order("distance", { ascending: true }).limit(count);
        if (error) throw error;
        return new Response(JSON.stringify(data), { status: 200 });
      }
    }
    return new Response("Not Found", { status: 404 });
  } catch (error) {
    return new Response(JSON.stringify({ error: error.message }), { status: 500 });
  }
});
